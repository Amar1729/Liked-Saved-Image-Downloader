#========================================
# Reddit Settings
#========================================

# Enter your username in password, with no quotes and no /u/
# Note that I am NOT responsible for security problems that may result
#  from using this script. You can check my code if you're paranoid,
#  but I'm not sure how PRAW handles raw text usernames and passwords.
Username=
Password=

# You need OAuth tokens to run the script. To get them follow these steps:
#	1. Go to https://www.reddit.com/prefs/apps/ (while signed in to reddit)
#	2. Scroll down to the bottom and click "create app" (something like that)
#	3. Fill in the fields as such:
#		name: Reddit Liked-Saved Image Downloader
#		Choose "script" as the type
#		about url: https://github.com/makuto/redditLikedSavedImageDownloader
# 		redirect uri: http://localhost:8080
#	4. Click create app
#	5. Copy the text which is right below "personal use script" here:

Client_id=

#		(should look like "J9-x99_-btqndQ" or something (it'll be different for your app)
#	6. Finally, copy the text after "Secret" here:

Client_secret=

#		(should look like "1zvtQjDZLMmehC2Qps7DdOl4iiQ" (different for your app)
#
# Yes, this process is a pain in the ass, but it's for your own security
# (see https://praw.readthedocs.io/en/latest/getting_started/authentication.html)

# Increase this value to 1000 or so to get more submissions
Reddit_Total_requests=400

Reddit_Save_Liked=True
Reddit_Save_Saved=True
Reddit_Save_Comments=True

#========================================
# General Settings
#========================================

#
# Set this to false to actually download images!
#
Should_soft_retrieve=False

# Output directory relative to where you executed the script
Output_dir=output

# If you just ran the script and forgot to turn SHOULD_SOFT_RETRIEVE off, set this 
#  variable to True. It'll use the submissions it got last time and speed up the process
Use_cached_submissions=False

# If the script failed at say 70%, you could use toggle Use_cached_submissions and set this value to
#  69. The script would then restart 69% of the way into the cached submissions nearer to where you
#  left off. 
# The reason why this isn't default is because there might have been changes to the script which 
#  made previous submissions successfully download, so we always re-check submissions 
# Note that this command will skip roughly the same percentage of imgur albums too
Skip_n_percent_submissions=0

# Only output messages which are considered important (file saved, file unsupported)
Only_important_messages=True

#========================================
# Imgur API Settings
#========================================

# These need to be filled in so that the script can download Imgur albums. If not filled in,
#  imgur albums will be ignored. Single images will still be downloaded. I've filled in a public
#  imgur user's information. This isn't safe giving you hooligans the secret, but fuck it
# If you want to use your own Imgur Client, sign in to Imgur, then go to https://api.imgur.com/oauth2/addclient
#  and create your new client.
Imgur_client_id=bb24366c72e680f
Imgur_client_secret=bc4c25819c95f4b2214c01f155ece80d0cee4011

Should_download_albums=True

# If true, do not download single images, only submissions which are imgur albums
Only_download_albums=False

#========================================
# Tumblr Settings
#========================================

# Follow the same procedure as reddit for Tumblr
# Register the app here: https://www.tumblr.com/oauth/apps
# Then go here to get your tokens: https://api.tumblr.com/console
# (refer to https://github.com/tumblr/pytumblr for more details)

Tumblr_Client_id=
Tumblr_Client_secret=
Tumblr_Client_token=
Tumblr_Client_token_secret=

# Increase this value to get more submissions
Tumblr_Total_requests=400